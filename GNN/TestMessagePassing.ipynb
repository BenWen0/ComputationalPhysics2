{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch_geometric\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graphToData(file):\n",
    "    #data.x: Node feature matrix with shape [num_nodes, num_node_features]\n",
    "    #data.edge_index: Graph connectivity in COO format with shape [2, num_edges] and type torch.long\n",
    "    #data.edge_attr: Edge feature matrix with shape [num_edges, num_edge_features]\n",
    "    #data.y: Target to train against (may have arbitrary shape), e.g., node-level targets of shape [num_nodes, *] or graph-level targets of shape [1, *]\n",
    "    #data.pos: Node position matrix with shape [num_nodes, num_dimensions]\n",
    "\n",
    "    graph = np.load(file)\n",
    "    label = torch.tensor(graph[\"label\"], dtype=torch.float) #shape=[1, 4]\n",
    "    node_values = torch.tensor(graph[\"nodes\"], dtype=torch.float) #shape=[num_nodes, 1]\n",
    "    edge_values = torch.tensor(graph[\"edges\"], dtype=torch.float) #shape=[num_edges, 2]\n",
    "    adj_list = torch.tensor(graph[\"adj_list\"], dtype=torch.long) #shape=[num_edges, 2] <- needs to be reshaped (see pyg doc)\n",
    "    positions = torch.tensor(graph[\"positions\"], dtype=torch.float) #shape=[num_nodes, 2]\n",
    "    \n",
    "    return Data(x=node_values, edge_index=adj_list.t().contiguous(), edge_attr=edge_values, y=label, pos=positions)\n",
    "\n",
    "def loadData(num_graphs):\n",
    "\n",
    "    graphs = list()\n",
    "    print(\"load squares\")\n",
    "    for i in tqdm(range(num_graphs)):\n",
    "        file = f\"../GenData/squares/square_{i}.npz\"\n",
    "        graphs.append(graphToData(file))\n",
    "    \n",
    "    print(\"load rectangles\")\n",
    "    for i in tqdm(range(num_graphs)):\n",
    "        file = f\"../GenData/rectangles/rectangular_{i}.npz\"\n",
    "        graphs.append(graphToData(file))\n",
    "    \n",
    "    print(\"load hexagons\")\n",
    "    for i in tqdm(range(num_graphs)):\n",
    "        file = f\"../GenData/hexagons/hexagonal_{i}.npz\"\n",
    "        graphs.append(graphToData(file))\n",
    "    \n",
    "    print(\"load oblique\")\n",
    "    for i in tqdm(range(num_graphs)):\n",
    "        file = f\"../GenData/oblique/oblique_{i}.npz\"\n",
    "        graphs.append(graphToData(file))\n",
    "\n",
    "    return graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestLayer(torch_geometric.nn.MessagePassing):\n",
    "    def __init__(self, num_node_features_, num_edge_features_, size_nn_message_hidden, size_nn_update_hidden):\n",
    "        super().__init__(aggr=\"add\", flow=\"source_to_target\") #source_to_target: create message to node i if (j,i) is edge\n",
    "        self.num_node_features = num_node_features_\n",
    "        self.num_edge_features = num_edge_features_\n",
    "        self.nn_message = torch.nn.Sequential(\n",
    "            torch.nn.Linear(in_features=2*self.num_node_features + self.num_edge_features, out_features=size_nn_message_hidden, bias=True),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(size_nn_message_hidden, size_nn_message_hidden, bias=True),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(size_nn_message_hidden, out_features=num_node_features_, bias=True)\n",
    "        )\n",
    "\n",
    "        self.nn_update = torch.nn.Sequential(\n",
    "            torch.nn.Linear(in_features=2*self.num_node_features, out_features=size_nn_update_hidden, bias=True),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(size_nn_update_hidden, size_nn_update_hidden, bias=True),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(size_nn_update_hidden, out_features=num_node_features_, bias=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_list, edge_attr = data.x, data.edge_index, data.edge_attr\n",
    "        #print(\"data: \", data)\n",
    "        #print(\"x\", x)\n",
    "        out = self.propagate(edge_list, x=x, edge_attr=edge_attr) #calls message(), aggregate(), update()\n",
    "        return out #shape = [number of nodes, number of node features]\n",
    "\n",
    "    def message(self, x_i, x_j, edge_attr):\n",
    "        # _i = central node, _j = neighboring node\n",
    "        # x_i,j =[number of edges, number of node features]\n",
    "        # edge_attr = [number of edges, number of edge features]\n",
    "        # the node with node features x_i[k, :] is connected with the nodes having the features x_j[k, :]. The edge connecting these nodes has the features edge_attr[k,:]\n",
    "\n",
    "        #print(\"x_i: \", x_i)\n",
    "        #print(\"x_j: \", x_j)\n",
    "        #print(\"edge_attr: \", edge_attr)\n",
    "        #print(edge_attr)\n",
    "        vec_in = torch.cat((x_i, x_j, edge_attr), dim = 1) # shape = [num_edges, 2*number of node_features + number of edge_features]\n",
    "        #print(vec_in.shape)\n",
    "        message = self.nn_message(vec_in) #shape = [num_edges, num node features]\n",
    "        #print(message.shape)\n",
    "        return message #return the message that is passed to node x_i\n",
    "\n",
    "    def update(self, input, x):\n",
    "        #input = output from aggregation step -> input shape = [number of nodes, number of node features]\n",
    "        #x_i shape = [number of nodes, number of node_features]\n",
    "        #print(\"input: \", input)\n",
    "        vec_in = torch.cat((x, input), dim = 1) #shape = [number of nodes,2* number of node features]\n",
    "        updated_input = self.nn_update(vec_in) #shape = [number of nodes, number of node features]\n",
    "        #print(updated_input.shape)\n",
    "        return updated_input #these nodes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Test(torch.nn.Module):\n",
    "    def __init__(self, num_node_features_, num_edge_features_):\n",
    "        super().__init__()\n",
    "        #expect num_node_features_ = num_classes\n",
    "        self.test_layer1 = TestLayer(num_node_features_, num_edge_features_, 20, 20)\n",
    "        self.test_layer2 = TestLayer(num_node_features_, num_edge_features_, 20, 20)\n",
    "        self.test_layer3 = TestLayer(num_node_features_, num_edge_features_, 20, 20)\n",
    "    \n",
    "    def forward(self, data):\n",
    "        x = self.test_layer1(data)\n",
    "        x = torch.nn.functional.relu(x)\n",
    "\n",
    "        x = self.test_layer2(data)\n",
    "        x = torch.nn.functional.relu(x)\n",
    "\n",
    "        x = self.test_layer3(data) #shape=[number of nodes, number of node features=number of classe]\n",
    "        \n",
    "        logits = torch_geometric.nn.global_mean_pool(x, data.batch) #shape [number of batches, number of classes]\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(loader, model, loss_fn, optimizer, device):\n",
    "    total_num_dataset = len(loader.dataset)\n",
    "    model.train()\n",
    "    for batch_nr, batch_dat in enumerate(loader):\n",
    "        batch_dat = batch_dat.to(device)\n",
    "        #print(batch_dat)\n",
    "        #print(batch_dat.num_graphs)\n",
    "        pred = model(batch_dat)\n",
    "        #print(pred.shape)\n",
    "        loss = loss_fn(pred, batch_dat.y)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch_nr % 20 == 0:\n",
    "            loss, current = loss.item(), (batch_nr + 1)*len(batch_dat)\n",
    "            print(f\"loss: {loss:>7f} [{current:>5d}/{total_num_dataset:>5d}]\")\n",
    "\n",
    "def test(loader, model, loss_fn, device):\n",
    "    size = len(loader.dataset)\n",
    "    num_batches = len(loader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            batch = batch.to(device)\n",
    "            pred = model(batch)\n",
    "            test_loss += loss_fn(pred, batch.y).item()\n",
    "            correct += (pred.argmax(dim=1) == batch.y.argmax(dim=1)).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /=size\n",
    "    print(f\"Test Error:\\n Accuracy: {(100*correct):>0.1f}%, Avg_loss: {test_loss:>8f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load squares\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:02<00:00, 482.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load rectangles\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:02<00:00, 372.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load hexagons\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:01<00:00, 504.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load oblique\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:02<00:00, 499.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3200\n",
      "DataBatch(x=[3200, 4], edge_index=[2, 12330], edge_attr=[12330, 2], y=[32, 4], pos=[3200, 2], batch=[3200], ptr=[33])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#load data\n",
    "import random\n",
    "data_list = loadData(1000)\n",
    "random.shuffle(data_list)\n",
    "\n",
    "train_dataloader = DataLoader(data_list[:int(0.8*len(data_list))], batch_size=32, shuffle=True)\n",
    "test_dataloader = DataLoader(data_list[int(0.8*len(data_list)):], batch_size=32, shuffle=True)\n",
    "print(len(train_dataloader.dataset))\n",
    "print(next(iter(train_dataloader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x = torch.tensor([[10, 10], [20, 20], [30, 30]], dtype=torch.float)\n",
    "#edge_index = torch.tensor([[0, 1, 2, 2], \n",
    "#                           [1, 0, 1, 2]], dtype=torch.long)\n",
    "#edge_attr = torch.tensor([[-1, -1], [-2, -2], [-3, -3], [-4, -4]], dtype=torch.float)\n",
    "#dat = Data(x=x, edge_index=edge_index, edge_attr=edge_attr)\n",
    "#dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = Test(num_node_features_=2, num_edge_features_=2)\n",
    "#res = model(dat)\n",
    "#print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1\n",
      "----------------------------------------\n",
      "loss: 1.422056 [   32/ 3200]\n",
      "loss: 0.741107 [  672/ 3200]\n",
      "loss: 0.311688 [ 1312/ 3200]\n",
      "loss: 0.108445 [ 1952/ 3200]\n",
      "loss: 0.259366 [ 2592/ 3200]\n",
      "Test Error:\n",
      " Accuracy: 92.6%, Avg_loss: 0.201854\n",
      "\n",
      "\n",
      "Epoch 2\n",
      "----------------------------------------\n",
      "loss: 0.281923 [   32/ 3200]\n",
      "loss: 0.463477 [  672/ 3200]\n",
      "loss: 0.009581 [ 1312/ 3200]\n",
      "loss: 0.022929 [ 1952/ 3200]\n",
      "loss: 0.015220 [ 2592/ 3200]\n",
      "Test Error:\n",
      " Accuracy: 99.8%, Avg_loss: 0.006577\n",
      "\n",
      "\n",
      "Epoch 3\n",
      "----------------------------------------\n",
      "loss: 0.002859 [   32/ 3200]\n",
      "loss: 0.001444 [  672/ 3200]\n",
      "loss: 0.002573 [ 1312/ 3200]\n",
      "loss: 0.001656 [ 1952/ 3200]\n",
      "loss: 0.000319 [ 2592/ 3200]\n",
      "Test Error:\n",
      " Accuracy: 100.0%, Avg_loss: 0.001696\n",
      "\n",
      "\n",
      "Epoch 4\n",
      "----------------------------------------\n",
      "loss: 0.000439 [   32/ 3200]\n",
      "loss: 0.241243 [  672/ 3200]\n",
      "loss: 0.000708 [ 1312/ 3200]\n",
      "loss: 0.001038 [ 1952/ 3200]\n",
      "loss: 0.018305 [ 2592/ 3200]\n",
      "Test Error:\n",
      " Accuracy: 100.0%, Avg_loss: 0.013521\n",
      "\n",
      "\n",
      "Epoch 5\n",
      "----------------------------------------\n",
      "loss: 0.012544 [   32/ 3200]\n",
      "loss: 0.015098 [  672/ 3200]\n",
      "loss: 0.001194 [ 1312/ 3200]\n",
      "loss: 0.000724 [ 1952/ 3200]\n",
      "loss: 0.000643 [ 2592/ 3200]\n",
      "Test Error:\n",
      " Accuracy: 100.0%, Avg_loss: 0.000961\n",
      "\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "model = Test(num_node_features_=4, num_edge_features_=2)\n",
    "model.to(device)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-2)\n",
    "\n",
    "epochs = 5\n",
    "for t in range(epochs):\n",
    "    print(f\"\\nEpoch {t+1}\\n----------------------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer, device)\n",
    "    test(test_dataloader, model, loss_fn, device)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
