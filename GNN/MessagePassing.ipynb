{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch_geometric\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graphToData(file):\n",
    "    #data.x: Node feature matrix with shape [num_nodes, num_node_features]\n",
    "    #data.edge_index: Graph connectivity in COO format with shape [2, num_edges] and type torch.long\n",
    "    #data.edge_attr: Edge feature matrix with shape [num_edges, num_edge_features]\n",
    "    #data.y: Target to train against (may have arbitrary shape), e.g., node-level targets of shape [num_nodes, *] or graph-level targets of shape [1, *]\n",
    "    #data.pos: Node position matrix with shape [num_nodes, num_dimensions]\n",
    "\n",
    "    graph = np.load(file)\n",
    "    label = torch.tensor(graph[\"label\"], dtype=torch.float) #shape=[1, num_classes]\n",
    "    node_values = torch.tensor(graph[\"nodes\"], dtype=torch.float) #shape=[num_nodes, num_node_values]\n",
    "    edge_values = torch.tensor(graph[\"edges\"], dtype=torch.float) #shape=[num_edges, num_edge_values]\n",
    "    adj_list = torch.tensor(graph[\"adj_list\"], dtype=torch.long) #shape=[num_edges, 2] <- needs to be reshaped (see pyg doc)\n",
    "    \n",
    "    positions = torch.tensor(graph[\"positions\"], dtype=torch.float) #shape=[num_nodes, 2] in 2d, [num_nodes, 3] in 3d, <- wird fürs Training überhaupt gar nicht gebraucht\n",
    "    \n",
    "    return Data(x=node_values, edge_index=adj_list.t().contiguous(), edge_attr=edge_values, y=label, pos=positions)\n",
    "\n",
    "def loadData(root_dir):\n",
    "    graphs = list()\n",
    "    for subdir, dirs, files in os.walk(root_dir):\n",
    "        print(subdir)\n",
    "        for file in tqdm(files):\n",
    "            path = os.path.join(subdir, file)\n",
    "            graphs.append(graphToData(path))\n",
    "    return graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNNLayer(torch_geometric.nn.MessagePassing):\n",
    "    def __init__(self, num_node_features_in, num_node_features_out, num_edge_features, \n",
    "                 num_hidden_layers_message, num_hidden_layers_update,\n",
    "                 size_nn_message_hidden, size_nn_update_hidden):\n",
    "        super().__init__(aggr=\"add\", flow=\"source_to_target\") #source_to_target: create message to node i if (j,i) is edge\n",
    "        self.num_node_features_in = num_node_features_in\n",
    "        self.num_node_features_out = num_node_features_out\n",
    "        self.num_edge_features = num_edge_features\n",
    "\n",
    "        #message neural network:\n",
    "        #size of input layers is always 2*number of node features (in) + number of edge features\n",
    "        #size of output layer is always number of node features out\n",
    "        #size of hidden layers is always size_nn_message_hidden\n",
    "        self.layers_message = list()\n",
    "        self.layers_message.append(\n",
    "            torch.nn.Linear(in_features=2*self.num_node_features_in + self.num_edge_features, out_features=size_nn_message_hidden, bias=True)\n",
    "        )\n",
    "        self.layers_message.append(\n",
    "            torch.nn.ReLU()\n",
    "        )\n",
    "        for _ in range(num_hidden_layers_message - 1):\n",
    "            self.layers_message.append(\n",
    "                torch.nn.Linear(in_features=size_nn_message_hidden, out_features=size_nn_message_hidden, bias=True)\n",
    "            )\n",
    "            self.layers_message.append(\n",
    "                torch.nn.ReLU()\n",
    "            )\n",
    "        self.layers_message.append(\n",
    "            torch.nn.Linear(size_nn_message_hidden, out_features=num_node_features_out, bias=True)\n",
    "        )\n",
    "        self.nn_message = torch.nn.ModuleList(self.layers_message)\n",
    "\n",
    "        #update neural network:\n",
    "        #size of input layer is always number of node features out + number of node features in\n",
    "        #size of output layer is always number of node features out\n",
    "        #size of hidden layers is always size_nn_update_hidden\n",
    "\n",
    "        self.layers_update = list()\n",
    "        self.layers_update.append(\n",
    "            torch.nn.Linear(in_features=self.num_node_features_out + self.num_node_features_in, out_features=size_nn_update_hidden, bias=True),\n",
    "        )\n",
    "        self.layers_update.append(\n",
    "            torch.nn.ReLU()\n",
    "        )\n",
    "        for _ in range(num_hidden_layers_update - 1):\n",
    "            self.layers_update.append(\n",
    "                torch.nn.Linear(in_features=size_nn_update_hidden, out_features=size_nn_update_hidden, bias=True),\n",
    "            )\n",
    "            self.layers_update.append(\n",
    "                torch.nn.ReLU()\n",
    "            )\n",
    "        self.layers_update.append(\n",
    "            torch.nn.Linear(in_features=size_nn_update_hidden, out_features=num_node_features_out, bias=True)\n",
    "        )\n",
    "        self.nn_update = torch.nn.ModuleList(self.layers_update)\n",
    "    \n",
    "    def forward(self, x, edge_list, edge_attr):\n",
    "        out = self.propagate(edge_list, x=x, edge_attr=edge_attr) #calls message(), aggregate(), update()\n",
    "        return out #shape = [number of nodes, number of node features]\n",
    "\n",
    "    def message(self, x_i, x_j, edge_attr):\n",
    "        # _i = central node, _j = neighboring node\n",
    "        # x_i,j =[number of edges, number of node features]\n",
    "        # edge_attr = [number of edges, number of edge features]\n",
    "        # the node with node features x_i[k, :] is connected with the nodes having the features x_j[k, :]. The edge connecting these nodes has the features edge_attr[k,:]\n",
    "\n",
    "        vec_in = torch.cat((x_i, x_j, edge_attr), dim = 1) # shape = [num_edges, 2*number of node_features + number of edge_features]\n",
    "        #message = self.nn_message(vec_in) #shape = [num_edges, num node features]\n",
    "        for i in range(len(self.nn_message)):\n",
    "            vec_in = self.nn_message[i](vec_in)\n",
    "        return vec_in #return the message that is passed to node x_i\n",
    "\n",
    "    def update(self, input, x):\n",
    "        #input = output from aggregation step -> input shape = [number of nodes, number of node features]\n",
    "        #x_i shape = [number of nodes, number of node_features]\n",
    "        \n",
    "        vec_in = torch.cat((x, input), dim = 1) #shape = [number of nodes, 2* number of node features]\n",
    "        #updated_input = self.nn_update(vec_in) #shape = [number of nodes, number of node features]\n",
    "        for i in range(len(self.nn_update)):\n",
    "            vec_in = self.nn_update[i](vec_in)\n",
    "        return vec_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Test(torch.nn.Module):\n",
    "    def __init__(self, num_node_features, num_classes, num_edge_features, \n",
    "                 num_additional_layers, num_hidden_layers_message, num_hidden_layers_update,\n",
    "                 width_nn_message_hidden, width_nn_update_hidden):\n",
    "        super().__init__()\n",
    "        #from GNN Layer: \n",
    "        # def __init__(self, num_node_features_in, num_node_features_out, num_edge_features, \n",
    "        #         num_hidden_layers_message, num_hidden_layers_update,\n",
    "        #         size_nn_message_hidden, size_nn_update_hidden):\n",
    "\n",
    "        self.first_layer = GNNLayer(num_node_features, num_classes, num_edge_features,\n",
    "                                    num_hidden_layers_message, num_hidden_layers_update,\n",
    "                                    width_nn_message_hidden, width_nn_update_hidden)\n",
    "\n",
    "        self.layers = list()\n",
    "        for _ in range(num_additional_layers):\n",
    "            self.layers.append(GNNLayer(num_classes, num_classes, num_edge_features, \n",
    "                                        num_hidden_layers_message, num_hidden_layers_update,\n",
    "                                        width_nn_message_hidden, width_nn_update_hidden\n",
    "                                        ))\n",
    "        self.layers = torch.nn.ModuleList(self.layers)\n",
    "        \n",
    "        self.last_layer = GNNLayer(num_classes, num_classes, num_edge_features, \n",
    "                                   num_hidden_layers_message, num_hidden_layers_update,\n",
    "                                   width_nn_message_hidden, width_nn_update_hidden)\n",
    "        \n",
    "    def forward(self, batch_dat):\n",
    "        x, edge_list, edge_attr, batch = batch_dat.x, batch_dat.edge_index, batch_dat.edge_attr, batch_dat.batch\n",
    "        x = self.first_layer(x, edge_list, edge_attr)\n",
    "        x = torch.nn.functional.relu(x)\n",
    "        \n",
    "        for i in range(len(self.layers)):\n",
    "            x = self.layers[i](x, edge_list, edge_attr)\n",
    "            x = torch.nn.functional.relu(x)\n",
    "\n",
    "        x = self.last_layer(x, edge_list, edge_attr) #shape=[number of nodes, number of node features=number of classe]\n",
    "        logits = torch_geometric.nn.global_mean_pool(x, batch) #shape [number of batches, number of classes]\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(loader, model, loss_fn, optimizer, device, print_log=True, save=False, file_save=\"\"):\n",
    "    total_num_dataset = len(loader.dataset)\n",
    "    model.train()\n",
    "    loss_save = list()\n",
    "    for batch_nr, batch_dat in enumerate(loader):\n",
    "        batch_dat = batch_dat.to(device)\n",
    "        pred = model(batch_dat)\n",
    "        loss = loss_fn(pred, batch_dat.y)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        if print_log and batch_nr % 50 == 0:\n",
    "            loss_, current = loss.item(), (batch_nr + 1)*len(batch_dat)\n",
    "            print(f\"loss: {loss_:>7f} [{current:>5d}/{total_num_dataset:>5d}]\")\n",
    "        if save:\n",
    "            loss_ = loss.item()\n",
    "            loss_save.append(loss_)\n",
    "    if save:\n",
    "        np.savetxt(fname=file_save, X=loss_save)\n",
    "\n",
    "\n",
    "def test(loader, model, loss_fn, device, print_log=True, save=False, file_save=\"\"):\n",
    "    size = len(loader.dataset)\n",
    "    num_batches = len(loader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            batch = batch.to(device)\n",
    "            pred = model(batch)\n",
    "            test_loss += loss_fn(pred, batch.y).item()\n",
    "            correct += (pred.argmax(dim=1) == batch.y.argmax(dim=1)).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /=size\n",
    "    if print_log:\n",
    "        print(f\"Test Error:\\n Accuracy: {(100*correct):>0.1f}%, Avg_loss: {test_loss:>8f}\\n\")\n",
    "    if save:\n",
    "        f = open(file_save, \"a+\")\n",
    "        f.write(f\"{test_loss},{correct}\\n\")\n",
    "        f.close()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../GenData/Data3d/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../GenData/Data3d/rhombohedral\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2302/2302 [00:04<00:00, 537.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../GenData/Data3d/orthorhombic\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13616/13616 [00:33<00:00, 402.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../GenData/Data3d/tetragonal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6924/6924 [00:14<00:00, 480.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../GenData/Data3d/monoclinic\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6850/6850 [00:14<00:00, 465.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../GenData/Data3d/cubic\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10500/10500 [00:26<00:00, 401.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../GenData/Data3d/triclinic\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1191/1191 [00:02<00:00, 524.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../GenData/Data3d/hexagonal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3456/3456 [00:06<00:00, 515.70it/s]\n"
     ]
    }
   ],
   "source": [
    "#load data\n",
    "import random\n",
    "data_list = loadData(\"../GenData/Data3d/\")\n",
    "random.shuffle(data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35871\n",
      "DataBatch(x=[6148, 1], edge_index=[2, 52892], edge_attr=[52892, 3], y=[32, 28], pos=[6148, 3], batch=[6148], ptr=[33])\n"
     ]
    }
   ],
   "source": [
    "train_dataloader = DataLoader(data_list[:int(0.8*len(data_list))], batch_size=32, shuffle=True)\n",
    "test_dataloader = DataLoader(data_list[int(0.8*len(data_list)):], batch_size=32, shuffle=True)\n",
    "print(len(train_dataloader.dataset))\n",
    "print(next(iter(train_dataloader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [1:33:45<00:00, 5625.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#2d: num_edge_features=2, num_classes=5\n",
    "#3d: num_edge_features=3, num_classes=28\n",
    "\n",
    "#from Test:\n",
    "# def __init__(self, num_node_features, num_classes, num_edge_features, \n",
    "#              num_additional_layers, num_hidden_layers_message, num_hidden_layers_update,\n",
    "#               width_nn_message_hidden, width_nn_update_hidden):\n",
    "\n",
    "#settings for 2d:\n",
    "#add_layers = [2]\n",
    "#hidd_mess = [1, 2, 3]\n",
    "#hidd_updt = [1, 2]\n",
    "#width_mess = [10, 20, 30]\n",
    "#width_upd = [5, 10]\n",
    "#repeat = 1\n",
    "\n",
    "#settings for 3d (best model):\n",
    "#add_layers = [2]\n",
    "#hidd_mess = [2]\n",
    "#hidd_updt = [1]\n",
    "#width_mess = [30]\n",
    "#width_upd = [10]\n",
    "#repeat = 5\n",
    "\n",
    "#settings for 3d (worst model):\n",
    "add_layers = [2]\n",
    "hidd_mess = [3]\n",
    "hidd_updt = [2]\n",
    "width_mess = [30]\n",
    "width_upd = [5]\n",
    "repeat = 5\n",
    "\n",
    "skip = []\n",
    "\n",
    "comb = [(al, hm, hu, wm, wu) for al in add_layers for hm in hidd_mess for hu in hidd_updt for wm in width_mess for wu in width_upd]\n",
    "for (al, hm, hu, wm, wu) in tqdm(comb):\n",
    "    if (al, hm, hu, wm, wu) in skip: continue\n",
    "    for rep in range(repeat):\n",
    "        model = Test(num_node_features=1, num_edge_features=3, num_classes=28,\n",
    "                     num_additional_layers=al, num_hidden_layers_message=hm, num_hidden_layers_update=hu,\n",
    "                     width_nn_message_hidden=wm, width_nn_update_hidden=wu)\n",
    "        model.to(device)\n",
    "        loss_fn = torch.nn.CrossEntropyLoss()\n",
    "        optimizer = torch.optim.NAdam(model.parameters())\n",
    "\n",
    "        epochs = 30\n",
    "        file_train = f\"run_al2_{hm}_{hu}_{wm}_{wu}_train.txt\"\n",
    "        file_test = f\"run_al2_{hm}_{hu}_{wm}_{wu}_test.txt\"\n",
    "        if repeat > 1:\n",
    "            file_train = f\"run{rep}_al2_{hm}_{hu}_{wm}_{wu}_train.txt\"\n",
    "            file_test = f\"run{rep}_al2_{hm}_{hu}_{wm}_{wu}_test.txt\"\n",
    "        for t in range(epochs):\n",
    "            #print(f\"\\nEpoch {t+1}\\n----------------------------------------\")\n",
    "            train(train_dataloader, model, loss_fn, optimizer, device, print_log=False, save=True, file_save=file_train)\n",
    "            test(test_dataloader, model, loss_fn, device, print_log=False, save=True, file_save=file_test)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
