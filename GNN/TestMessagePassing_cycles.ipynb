{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch_geometric\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graphToData(file, label_):\n",
    "    graph = np.load(file)\n",
    "    num_nodes = len(graph[\"nodes\"])\n",
    "    num_edges = len(graph[\"edges\"])\n",
    "    label = torch.tensor([label_], dtype=torch.float) #shape=[1, num_classes]\n",
    "    node_values = torch.tensor(np.zeros(shape=(num_nodes, 1)), dtype=torch.float) #shape=[num_nodes, num_node_values]\n",
    "    edge_values = torch.tensor(np.zeros(shape=(num_edges, 1)), dtype=torch.float) #shape=[num_edges, num_edge_values]\n",
    "    adj_list = torch.tensor(graph[\"edges\"], dtype=torch.long) #shape=[num_edges, 2] <- needs to be reshaped (see pyg doc)\n",
    "    #positions = torch.tensor(graph[\"positions\"], dtype=torch.float) #shape=[num_nodes, 2]\n",
    "    \n",
    "    return Data(x=node_values, edge_index=adj_list.t().contiguous(), edge_attr=edge_values, y=label)\n",
    "def loadData(root_dir):\n",
    "    graphs = list()\n",
    "    for subdir, dirs, files in os.walk(root_dir):\n",
    "        label= [1, 0] if subdir==\"../GenData/DataCycle/cycles\" else [0, 1]\n",
    "        print(subdir, label)\n",
    "        for file in tqdm(files):\n",
    "            path = os.path.join(subdir, file)\n",
    "            graphs.append(graphToData(path, label))\n",
    "    return graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestLayer(torch_geometric.nn.MessagePassing):\n",
    "    def __init__(self, num_node_features_in, num_node_features_out, num_edge_features_, size_nn_message_hidden, size_nn_update_hidden):\n",
    "        super().__init__(aggr=\"add\", flow=\"source_to_target\") #source_to_target: create message to node i if (j,i) is edge\n",
    "        self.num_node_features_in = num_node_features_in\n",
    "        self.num_node_features_out = num_node_features_out\n",
    "        self.num_edge_features = num_edge_features_\n",
    "        self.nn_message = torch.nn.Sequential(\n",
    "            torch.nn.Linear(in_features=2*self.num_node_features_in + self.num_edge_features, out_features=size_nn_message_hidden, bias=True),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(size_nn_message_hidden, out_features=num_node_features_out, bias=True)\n",
    "        )\n",
    "\n",
    "        self.nn_update = torch.nn.Sequential(\n",
    "            torch.nn.Linear(in_features=self.num_node_features_out + self.num_node_features_in, out_features=size_nn_update_hidden, bias=True),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(size_nn_update_hidden, out_features=num_node_features_out, bias=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, edge_list, edge_attr):\n",
    "        out = self.propagate(edge_list, x=x, edge_attr=edge_attr) #calls message(), aggregate(), update()\n",
    "        return out #shape = [number of nodes, number of node features]\n",
    "\n",
    "    def message(self, x_i, x_j, edge_attr):\n",
    "        vec_in = torch.cat((x_i, x_j, edge_attr), dim = 1) # shape = [num_edges, 2*number of node_features + number of edge_features]\n",
    "        message = self.nn_message(vec_in) #shape = [num_edges, num node features]\n",
    "        return message #return the message that is passed to node x_i\n",
    "\n",
    "    def update(self, input, x):\n",
    "        vec_in = torch.cat((x, input), dim = 1) #shape = [number of nodes, 2* number of node features]\n",
    "        updated_input = self.nn_update(vec_in) #shape = [number of nodes, number of node features]\n",
    "        return updated_input #these nodes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Test(torch.nn.Module):\n",
    "    def __init__(self, num_node_features_, num_classes, num_edge_features_, num_layers, num_neurons_message, num_neurons_update):\n",
    "        super().__init__()\n",
    "        #expect num_node_features_ = num_classes\n",
    "        num_hidden_node_features = 10\n",
    "        self.first_layer = TestLayer(num_node_features_, num_hidden_node_features, num_edge_features_, num_neurons_message, num_neurons_update)\n",
    "\n",
    "        self.num_layers = num_layers\n",
    "        self.layers = list()\n",
    "        for _ in range(self.num_layers):\n",
    "            self.layers.append(TestLayer(num_hidden_node_features, num_hidden_node_features, num_edge_features_, num_neurons_message, num_neurons_update))\n",
    "        self.layers = torch.nn.ModuleList(self.layers)\n",
    "\n",
    "        self.last_layer = TestLayer(num_hidden_node_features, num_classes, num_edge_features_, num_neurons_message, num_neurons_update)\n",
    "    \n",
    "    def forward(self, batch_dat):\n",
    "        x, edge_list, edge_attr, batch = batch_dat.x, batch_dat.edge_index, batch_dat.edge_attr, batch_dat.batch\n",
    "\n",
    "        x = self.first_layer(x, edge_list, edge_attr)\n",
    "        x = torch.nn.functional.relu(x)\n",
    "\n",
    "        for i in range(self.num_layers):\n",
    "            x = self.layers[i](x, edge_list, edge_attr)\n",
    "            x = torch.nn.functional.relu(x)\n",
    "\n",
    "        x = self.last_layer(x, edge_list, edge_attr) #shape=[number of nodes, number of node features=number of classe]       \n",
    "        logits = torch_geometric.nn.global_mean_pool(x, batch) #shape [number of batches, number of classes]\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(loader, model, loss_fn, optimizer, device, save=False, file_save=\"\"):\n",
    "    total_num_dataset = len(loader.dataset)\n",
    "    model.train()\n",
    "    loss_save = list()\n",
    "    for batch_nr, batch_dat in enumerate(loader):\n",
    "        batch_dat = batch_dat.to(device)\n",
    "        pred = model(batch_dat)\n",
    "        loss = loss_fn(pred, batch_dat.y)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch_nr % 50 == 0:\n",
    "            loss_, current = loss.item(), (batch_nr + 1)*len(batch_dat)\n",
    "            print(f\"loss: {loss_:>7f} [{current:>5d}/{total_num_dataset:>5d}]\")\n",
    "        if save:\n",
    "            loss_ = loss.item()\n",
    "            loss_save.append(loss_)\n",
    "    if save:\n",
    "        np.savetxt(fname=file_save, X=loss_save)\n",
    "\n",
    "\n",
    "def test(loader, model, loss_fn, device, save=False, file_save=\"\"):\n",
    "    size = len(loader.dataset)\n",
    "    num_batches = len(loader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            batch = batch.to(device)\n",
    "            pred = model(batch)\n",
    "            test_loss += loss_fn(pred, batch.y).item()\n",
    "            correct += (pred.argmax(dim=1) == batch.y.argmax(dim=1)).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /=size\n",
    "    print(f\"Test Error:\\n Accuracy: {(100*correct):>0.1f}%, Avg_loss: {test_loss:>8f}\\n\")\n",
    "    if save:\n",
    "        #if not os.path.exists(file_save):\n",
    "        #    os.mknod(file_save)\n",
    "        f = open(file_save, \"a+\")\n",
    "        f.write(f\"{test_loss},{correct}\\n\")\n",
    "        f.close()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../GenData/DataCycle/ [0, 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../GenData/DataCycle/no_cycles [0, 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 37909/37909 [00:28<00:00, 1333.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../GenData/DataCycle/cycles [1, 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 62091/62091 [00:45<00:00, 1350.82it/s]\n"
     ]
    }
   ],
   "source": [
    "#load data\n",
    "import random\n",
    "data_list = loadData(\"../GenData/DataCycle/\")\n",
    "random.shuffle(data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80000\n",
      "DataBatch(x=[6538, 1], edge_index=[2, 3626], edge_attr=[3626, 1], y=[64, 2], batch=[6538], ptr=[65])\n"
     ]
    }
   ],
   "source": [
    "#data_list = stephen.ThreeDGraphDataset(root='3D_graphs_stephen', n_graphs_per_type=300)\n",
    "\n",
    "train_dataloader = DataLoader(data_list[:int(0.8*len(data_list))], batch_size=64, shuffle=True)\n",
    "test_dataloader = DataLoader(data_list[int(0.8*len(data_list)):], batch_size=64, shuffle=True)\n",
    "print(len(train_dataloader.dataset))\n",
    "print(next(iter(train_dataloader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Without Training\n",
      "----------------------------------------\n",
      "Test Error:\n",
      " Accuracy: 38.0%, Avg_loss: 0.855650\n",
      "\n",
      "\n",
      "Epoch 1\n",
      "----------------------------------------\n",
      "loss: 0.787777 [   64/80000]\n",
      "loss: 0.571101 [ 3264/80000]\n",
      "loss: 0.528373 [ 6464/80000]\n",
      "loss: 0.541943 [ 9664/80000]\n",
      "loss: 0.534896 [12864/80000]\n",
      "loss: 0.420394 [16064/80000]\n",
      "loss: 0.427157 [19264/80000]\n",
      "loss: 0.373963 [22464/80000]\n",
      "loss: 0.381496 [25664/80000]\n",
      "loss: 0.520375 [28864/80000]\n",
      "loss: 0.314667 [32064/80000]\n",
      "loss: 0.364242 [35264/80000]\n",
      "loss: 0.468905 [38464/80000]\n",
      "loss: 0.397001 [41664/80000]\n",
      "loss: 0.331911 [44864/80000]\n",
      "loss: 0.352866 [48064/80000]\n",
      "loss: 0.461573 [51264/80000]\n",
      "loss: 0.372134 [54464/80000]\n",
      "loss: 0.564648 [57664/80000]\n",
      "loss: 0.402252 [60864/80000]\n",
      "loss: 0.550198 [64064/80000]\n",
      "loss: 0.383926 [67264/80000]\n",
      "loss: 0.470245 [70464/80000]\n",
      "loss: 0.433342 [73664/80000]\n",
      "loss: 0.443953 [76864/80000]\n",
      "Test Error:\n",
      " Accuracy: 79.5%, Avg_loss: 0.421242\n",
      "\n",
      "\n",
      "Epoch 2\n",
      "----------------------------------------\n",
      "loss: 0.389523 [   64/80000]\n",
      "loss: 0.328028 [ 3264/80000]\n",
      "loss: 0.442687 [ 6464/80000]\n",
      "loss: 0.497591 [ 9664/80000]\n",
      "loss: 0.344007 [12864/80000]\n",
      "loss: 0.509980 [16064/80000]\n",
      "loss: 0.366962 [19264/80000]\n",
      "loss: 0.474461 [22464/80000]\n",
      "loss: 0.491597 [25664/80000]\n",
      "loss: 0.398049 [28864/80000]\n",
      "loss: 0.549353 [32064/80000]\n",
      "loss: 0.439436 [35264/80000]\n",
      "loss: 0.442886 [38464/80000]\n",
      "loss: 0.290740 [41664/80000]\n",
      "loss: 0.387915 [44864/80000]\n",
      "loss: 0.393538 [48064/80000]\n",
      "loss: 0.401906 [51264/80000]\n",
      "loss: 0.389896 [54464/80000]\n",
      "loss: 0.530159 [57664/80000]\n",
      "loss: 0.458741 [60864/80000]\n",
      "loss: 0.350221 [64064/80000]\n",
      "loss: 0.384488 [67264/80000]\n",
      "loss: 0.275004 [70464/80000]\n",
      "loss: 0.494537 [73664/80000]\n",
      "loss: 0.331834 [76864/80000]\n",
      "Test Error:\n",
      " Accuracy: 79.9%, Avg_loss: 0.416945\n",
      "\n",
      "\n",
      "Epoch 3\n",
      "----------------------------------------\n",
      "loss: 0.410787 [   64/80000]\n",
      "loss: 0.383944 [ 3264/80000]\n",
      "loss: 0.373180 [ 6464/80000]\n",
      "loss: 0.520212 [ 9664/80000]\n",
      "loss: 0.366862 [12864/80000]\n",
      "loss: 0.492457 [16064/80000]\n",
      "loss: 0.434435 [19264/80000]\n",
      "loss: 0.379095 [22464/80000]\n",
      "loss: 0.351843 [25664/80000]\n",
      "loss: 0.398561 [28864/80000]\n",
      "loss: 0.431816 [32064/80000]\n",
      "loss: 0.405406 [35264/80000]\n",
      "loss: 0.313303 [38464/80000]\n",
      "loss: 0.449562 [41664/80000]\n",
      "loss: 0.395294 [44864/80000]\n",
      "loss: 0.387558 [48064/80000]\n",
      "loss: 0.357409 [51264/80000]\n",
      "loss: 0.357084 [54464/80000]\n",
      "loss: 0.338199 [57664/80000]\n",
      "loss: 0.486615 [60864/80000]\n",
      "loss: 0.380237 [64064/80000]\n",
      "loss: 0.338576 [67264/80000]\n",
      "loss: 0.342795 [70464/80000]\n",
      "loss: 0.427341 [73664/80000]\n",
      "loss: 0.337458 [76864/80000]\n",
      "Test Error:\n",
      " Accuracy: 80.0%, Avg_loss: 0.413698\n",
      "\n",
      "\n",
      "Epoch 4\n",
      "----------------------------------------\n",
      "loss: 0.385105 [   64/80000]\n",
      "loss: 0.355212 [ 3264/80000]\n",
      "loss: 0.324838 [ 6464/80000]\n",
      "loss: 0.486010 [ 9664/80000]\n",
      "loss: 0.456294 [12864/80000]\n",
      "loss: 0.430530 [16064/80000]\n",
      "loss: 0.400256 [19264/80000]\n",
      "loss: 0.481496 [22464/80000]\n",
      "loss: 0.337561 [25664/80000]\n",
      "loss: 0.493888 [28864/80000]\n",
      "loss: 0.402257 [32064/80000]\n",
      "loss: 0.529269 [35264/80000]\n",
      "loss: 0.358555 [38464/80000]\n",
      "loss: 0.444096 [41664/80000]\n",
      "loss: 0.416899 [44864/80000]\n",
      "loss: 0.454254 [48064/80000]\n",
      "loss: 0.295806 [51264/80000]\n",
      "loss: 0.431623 [54464/80000]\n",
      "loss: 0.247795 [57664/80000]\n",
      "loss: 0.478000 [60864/80000]\n",
      "loss: 0.366220 [64064/80000]\n",
      "loss: 0.375589 [67264/80000]\n",
      "loss: 0.332750 [70464/80000]\n",
      "loss: 0.552979 [73664/80000]\n",
      "loss: 0.394276 [76864/80000]\n",
      "Test Error:\n",
      " Accuracy: 80.0%, Avg_loss: 0.413633\n",
      "\n",
      "\n",
      "Epoch 5\n",
      "----------------------------------------\n",
      "loss: 0.559392 [   64/80000]\n",
      "loss: 0.376428 [ 3264/80000]\n",
      "loss: 0.406926 [ 6464/80000]\n",
      "loss: 0.326362 [ 9664/80000]\n",
      "loss: 0.419341 [12864/80000]\n",
      "loss: 0.304452 [16064/80000]\n",
      "loss: 0.376318 [19264/80000]\n",
      "loss: 0.310598 [22464/80000]\n",
      "loss: 0.377672 [25664/80000]\n",
      "loss: 0.368068 [28864/80000]\n",
      "loss: 0.418323 [32064/80000]\n",
      "loss: 0.391778 [35264/80000]\n",
      "loss: 0.460921 [38464/80000]\n",
      "loss: 0.519440 [41664/80000]\n",
      "loss: 0.370765 [44864/80000]\n",
      "loss: 0.443224 [48064/80000]\n",
      "loss: 0.465989 [51264/80000]\n",
      "loss: 0.477965 [54464/80000]\n",
      "loss: 0.452022 [57664/80000]\n",
      "loss: 0.475693 [60864/80000]\n",
      "loss: 0.385651 [64064/80000]\n",
      "loss: 0.411270 [67264/80000]\n",
      "loss: 0.339492 [70464/80000]\n",
      "loss: 0.387631 [73664/80000]\n",
      "loss: 0.344541 [76864/80000]\n",
      "Test Error:\n",
      " Accuracy: 79.8%, Avg_loss: 0.416816\n",
      "\n",
      "\n",
      "Epoch 6\n",
      "----------------------------------------\n",
      "loss: 0.377735 [   64/80000]\n",
      "loss: 0.423889 [ 3264/80000]\n",
      "loss: 0.356360 [ 6464/80000]\n",
      "loss: 0.373024 [ 9664/80000]\n",
      "loss: 0.431245 [12864/80000]\n",
      "loss: 0.351412 [16064/80000]\n",
      "loss: 0.425728 [19264/80000]\n",
      "loss: 0.425578 [22464/80000]\n",
      "loss: 0.449837 [25664/80000]\n",
      "loss: 0.365768 [28864/80000]\n",
      "loss: 0.409580 [32064/80000]\n",
      "loss: 0.510312 [35264/80000]\n",
      "loss: 0.356666 [38464/80000]\n",
      "loss: 0.302740 [41664/80000]\n",
      "loss: 0.488285 [44864/80000]\n",
      "loss: 0.351463 [48064/80000]\n",
      "loss: 0.349579 [51264/80000]\n",
      "loss: 0.368439 [54464/80000]\n",
      "loss: 0.390193 [57664/80000]\n",
      "loss: 0.457656 [60864/80000]\n",
      "loss: 0.408458 [64064/80000]\n",
      "loss: 0.510618 [67264/80000]\n",
      "loss: 0.326519 [70464/80000]\n",
      "loss: 0.366688 [73664/80000]\n",
      "loss: 0.470237 [76864/80000]\n",
      "Test Error:\n",
      " Accuracy: 79.8%, Avg_loss: 0.419434\n",
      "\n",
      "\n",
      "Epoch 7\n",
      "----------------------------------------\n",
      "loss: 0.465812 [   64/80000]\n",
      "loss: 0.376572 [ 3264/80000]\n",
      "loss: 0.313447 [ 6464/80000]\n",
      "loss: 0.247292 [ 9664/80000]\n",
      "loss: 0.471996 [12864/80000]\n",
      "loss: 0.374338 [16064/80000]\n",
      "loss: 0.390587 [19264/80000]\n",
      "loss: 0.433456 [22464/80000]\n",
      "loss: 0.504235 [25664/80000]\n",
      "loss: 0.331567 [28864/80000]\n",
      "loss: 0.542053 [32064/80000]\n",
      "loss: 0.502293 [35264/80000]\n",
      "loss: 0.344939 [38464/80000]\n",
      "loss: 0.308989 [41664/80000]\n",
      "loss: 0.330679 [44864/80000]\n",
      "loss: 0.357810 [48064/80000]\n",
      "loss: 0.385717 [51264/80000]\n",
      "loss: 0.429228 [54464/80000]\n",
      "loss: 0.592781 [57664/80000]\n",
      "loss: 0.341149 [60864/80000]\n",
      "loss: 0.377747 [64064/80000]\n",
      "loss: 0.406383 [67264/80000]\n",
      "loss: 0.444255 [70464/80000]\n",
      "loss: 0.396623 [73664/80000]\n",
      "loss: 0.382103 [76864/80000]\n",
      "Test Error:\n",
      " Accuracy: 80.0%, Avg_loss: 0.410839\n",
      "\n",
      "\n",
      "Epoch 8\n",
      "----------------------------------------\n",
      "loss: 0.500049 [   64/80000]\n",
      "loss: 0.377712 [ 3264/80000]\n",
      "loss: 0.456675 [ 6464/80000]\n",
      "loss: 0.463814 [ 9664/80000]\n",
      "loss: 0.305482 [12864/80000]\n",
      "loss: 0.291788 [16064/80000]\n",
      "loss: 0.378387 [19264/80000]\n",
      "loss: 0.362440 [22464/80000]\n",
      "loss: 0.308608 [25664/80000]\n",
      "loss: 0.450998 [28864/80000]\n",
      "loss: 0.512571 [32064/80000]\n",
      "loss: 0.393665 [35264/80000]\n",
      "loss: 0.478584 [38464/80000]\n",
      "loss: 0.398389 [41664/80000]\n",
      "loss: 0.443964 [44864/80000]\n",
      "loss: 0.566170 [48064/80000]\n",
      "loss: 0.499182 [51264/80000]\n",
      "loss: 0.362250 [54464/80000]\n",
      "loss: 0.379955 [57664/80000]\n",
      "loss: 0.485465 [60864/80000]\n",
      "loss: 0.446550 [64064/80000]\n",
      "loss: 0.446891 [67264/80000]\n",
      "loss: 0.406321 [70464/80000]\n",
      "loss: 0.334603 [73664/80000]\n",
      "loss: 0.355449 [76864/80000]\n",
      "Test Error:\n",
      " Accuracy: 79.9%, Avg_loss: 0.413612\n",
      "\n",
      "\n",
      "Epoch 9\n",
      "----------------------------------------\n",
      "loss: 0.317589 [   64/80000]\n",
      "loss: 0.387849 [ 3264/80000]\n",
      "loss: 0.371723 [ 6464/80000]\n",
      "loss: 0.451258 [ 9664/80000]\n",
      "loss: 0.296800 [12864/80000]\n",
      "loss: 0.480238 [16064/80000]\n",
      "loss: 0.415961 [19264/80000]\n",
      "loss: 0.386081 [22464/80000]\n",
      "loss: 0.519309 [25664/80000]\n",
      "loss: 0.377589 [28864/80000]\n",
      "loss: 0.339174 [32064/80000]\n",
      "loss: 0.347658 [35264/80000]\n",
      "loss: 0.506118 [38464/80000]\n",
      "loss: 0.466781 [41664/80000]\n",
      "loss: 0.328459 [44864/80000]\n",
      "loss: 0.379648 [48064/80000]\n",
      "loss: 0.368107 [51264/80000]\n",
      "loss: 0.412215 [54464/80000]\n",
      "loss: 0.332183 [57664/80000]\n",
      "loss: 0.404093 [60864/80000]\n",
      "loss: 0.326759 [64064/80000]\n",
      "loss: 0.418665 [67264/80000]\n",
      "loss: 0.382800 [70464/80000]\n",
      "loss: 0.465746 [73664/80000]\n",
      "loss: 0.334844 [76864/80000]\n",
      "Test Error:\n",
      " Accuracy: 80.0%, Avg_loss: 0.411002\n",
      "\n",
      "\n",
      "Epoch 10\n",
      "----------------------------------------\n",
      "loss: 0.333162 [   64/80000]\n",
      "loss: 0.493923 [ 3264/80000]\n",
      "loss: 0.368121 [ 6464/80000]\n",
      "loss: 0.392339 [ 9664/80000]\n",
      "loss: 0.435191 [12864/80000]\n",
      "loss: 0.481384 [16064/80000]\n",
      "loss: 0.437454 [19264/80000]\n",
      "loss: 0.438600 [22464/80000]\n",
      "loss: 0.434787 [25664/80000]\n",
      "loss: 0.363923 [28864/80000]\n",
      "loss: 0.388494 [32064/80000]\n",
      "loss: 0.358940 [35264/80000]\n",
      "loss: 0.381922 [38464/80000]\n",
      "loss: 0.402142 [41664/80000]\n",
      "loss: 0.364142 [44864/80000]\n",
      "loss: 0.367767 [48064/80000]\n",
      "loss: 0.428646 [51264/80000]\n",
      "loss: 0.394093 [54464/80000]\n",
      "loss: 0.372161 [57664/80000]\n",
      "loss: 0.489894 [60864/80000]\n",
      "loss: 0.536975 [64064/80000]\n",
      "loss: 0.461496 [67264/80000]\n",
      "loss: 0.433496 [70464/80000]\n",
      "loss: 0.402037 [73664/80000]\n",
      "loss: 0.449449 [76864/80000]\n",
      "Test Error:\n",
      " Accuracy: 80.0%, Avg_loss: 0.411120\n",
      "\n",
      "\n",
      "Epoch 11\n",
      "----------------------------------------\n",
      "loss: 0.530033 [   64/80000]\n",
      "loss: 0.434486 [ 3264/80000]\n",
      "loss: 0.357197 [ 6464/80000]\n",
      "loss: 0.389270 [ 9664/80000]\n",
      "loss: 0.445698 [12864/80000]\n",
      "loss: 0.404023 [16064/80000]\n",
      "loss: 0.505092 [19264/80000]\n",
      "loss: 0.535157 [22464/80000]\n",
      "loss: 0.387351 [25664/80000]\n",
      "loss: 0.468829 [28864/80000]\n",
      "loss: 0.419967 [32064/80000]\n",
      "loss: 0.357036 [35264/80000]\n",
      "loss: 0.486989 [38464/80000]\n",
      "loss: 0.457011 [41664/80000]\n",
      "loss: 0.329896 [44864/80000]\n",
      "loss: 0.351648 [48064/80000]\n",
      "loss: 0.369971 [51264/80000]\n",
      "loss: 0.526904 [54464/80000]\n",
      "loss: 0.536807 [57664/80000]\n",
      "loss: 0.438665 [60864/80000]\n",
      "loss: 0.375205 [64064/80000]\n",
      "loss: 0.421088 [67264/80000]\n",
      "loss: 0.449444 [70464/80000]\n",
      "loss: 0.372160 [73664/80000]\n",
      "loss: 0.309668 [76864/80000]\n",
      "Test Error:\n",
      " Accuracy: 80.0%, Avg_loss: 0.410068\n",
      "\n",
      "\n",
      "Epoch 12\n",
      "----------------------------------------\n",
      "loss: 0.470402 [   64/80000]\n",
      "loss: 0.379881 [ 3264/80000]\n",
      "loss: 0.447666 [ 6464/80000]\n",
      "loss: 0.355989 [ 9664/80000]\n",
      "loss: 0.296471 [12864/80000]\n",
      "loss: 0.464102 [16064/80000]\n",
      "loss: 0.413160 [19264/80000]\n",
      "loss: 0.414996 [22464/80000]\n",
      "loss: 0.320951 [25664/80000]\n",
      "loss: 0.428813 [28864/80000]\n",
      "loss: 0.378007 [32064/80000]\n",
      "loss: 0.497732 [35264/80000]\n",
      "loss: 0.375361 [38464/80000]\n",
      "loss: 0.404626 [41664/80000]\n",
      "loss: 0.487727 [44864/80000]\n",
      "loss: 0.377576 [48064/80000]\n",
      "loss: 0.361620 [51264/80000]\n",
      "loss: 0.433248 [54464/80000]\n",
      "loss: 0.453570 [57664/80000]\n",
      "loss: 0.375638 [60864/80000]\n",
      "loss: 0.369386 [64064/80000]\n",
      "loss: 0.288357 [67264/80000]\n",
      "loss: 0.496983 [70464/80000]\n",
      "loss: 0.493494 [73664/80000]\n",
      "loss: 0.298692 [76864/80000]\n",
      "Test Error:\n",
      " Accuracy: 80.1%, Avg_loss: 0.409947\n",
      "\n",
      "\n",
      "Epoch 13\n",
      "----------------------------------------\n",
      "loss: 0.350517 [   64/80000]\n",
      "loss: 0.468092 [ 3264/80000]\n",
      "loss: 0.360398 [ 6464/80000]\n",
      "loss: 0.398891 [ 9664/80000]\n",
      "loss: 0.391314 [12864/80000]\n",
      "loss: 0.440963 [16064/80000]\n",
      "loss: 0.295615 [19264/80000]\n",
      "loss: 0.494140 [22464/80000]\n",
      "loss: 0.438340 [25664/80000]\n",
      "loss: 0.462652 [28864/80000]\n",
      "loss: 0.355915 [32064/80000]\n",
      "loss: 0.289425 [35264/80000]\n",
      "loss: 0.416260 [38464/80000]\n",
      "loss: 0.418211 [41664/80000]\n",
      "loss: 0.373458 [44864/80000]\n",
      "loss: 0.485820 [48064/80000]\n",
      "loss: 0.319075 [51264/80000]\n",
      "loss: 0.401295 [54464/80000]\n",
      "loss: 0.475006 [57664/80000]\n",
      "loss: 0.315394 [60864/80000]\n",
      "loss: 0.417513 [64064/80000]\n",
      "loss: 0.407897 [67264/80000]\n",
      "loss: 0.282094 [70464/80000]\n",
      "loss: 0.422915 [73664/80000]\n",
      "loss: 0.436818 [76864/80000]\n",
      "Test Error:\n",
      " Accuracy: 80.1%, Avg_loss: 0.411536\n",
      "\n",
      "\n",
      "Epoch 14\n",
      "----------------------------------------\n",
      "loss: 0.396447 [   64/80000]\n",
      "loss: 0.451059 [ 3264/80000]\n",
      "loss: 0.500517 [ 6464/80000]\n",
      "loss: 0.515766 [ 9664/80000]\n",
      "loss: 0.402866 [12864/80000]\n",
      "loss: 0.332758 [16064/80000]\n",
      "loss: 0.515418 [19264/80000]\n",
      "loss: 0.463330 [22464/80000]\n",
      "loss: 0.379514 [25664/80000]\n",
      "loss: 0.388065 [28864/80000]\n",
      "loss: 0.389517 [32064/80000]\n",
      "loss: 0.421337 [35264/80000]\n",
      "loss: 0.488789 [38464/80000]\n",
      "loss: 0.454370 [41664/80000]\n",
      "loss: 0.553208 [44864/80000]\n",
      "loss: 0.345365 [48064/80000]\n",
      "loss: 0.325412 [51264/80000]\n",
      "loss: 0.346787 [54464/80000]\n",
      "loss: 0.496726 [57664/80000]\n",
      "loss: 0.232278 [60864/80000]\n",
      "loss: 0.427351 [64064/80000]\n",
      "loss: 0.421905 [67264/80000]\n",
      "loss: 0.551305 [70464/80000]\n",
      "loss: 0.433357 [73664/80000]\n",
      "loss: 0.364641 [76864/80000]\n",
      "Test Error:\n",
      " Accuracy: 80.1%, Avg_loss: 0.411305\n",
      "\n",
      "\n",
      "Epoch 15\n",
      "----------------------------------------\n",
      "loss: 0.455339 [   64/80000]\n",
      "loss: 0.390553 [ 3264/80000]\n",
      "loss: 0.490327 [ 6464/80000]\n",
      "loss: 0.414734 [ 9664/80000]\n",
      "loss: 0.334096 [12864/80000]\n",
      "loss: 0.259631 [16064/80000]\n",
      "loss: 0.518672 [19264/80000]\n",
      "loss: 0.359056 [22464/80000]\n",
      "loss: 0.355303 [25664/80000]\n",
      "loss: 0.391583 [28864/80000]\n",
      "loss: 0.394378 [32064/80000]\n",
      "loss: 0.367343 [35264/80000]\n",
      "loss: 0.334763 [38464/80000]\n",
      "loss: 0.358221 [41664/80000]\n",
      "loss: 0.432100 [44864/80000]\n",
      "loss: 0.447930 [48064/80000]\n",
      "loss: 0.302137 [51264/80000]\n",
      "loss: 0.416183 [54464/80000]\n",
      "loss: 0.620890 [57664/80000]\n",
      "loss: 0.459119 [60864/80000]\n",
      "loss: 0.365941 [64064/80000]\n",
      "loss: 0.485110 [67264/80000]\n",
      "loss: 0.379643 [70464/80000]\n",
      "loss: 0.341353 [73664/80000]\n",
      "loss: 0.478285 [76864/80000]\n",
      "Test Error:\n",
      " Accuracy: 79.9%, Avg_loss: 0.415076\n",
      "\n",
      "\n",
      "Epoch 16\n",
      "----------------------------------------\n",
      "loss: 0.507376 [   64/80000]\n",
      "loss: 0.372162 [ 3264/80000]\n",
      "loss: 0.441177 [ 6464/80000]\n",
      "loss: 0.328459 [ 9664/80000]\n",
      "loss: 0.421493 [12864/80000]\n",
      "loss: 0.416477 [16064/80000]\n",
      "loss: 0.399493 [19264/80000]\n",
      "loss: 0.416278 [22464/80000]\n",
      "loss: 0.370634 [25664/80000]\n",
      "loss: 0.525611 [28864/80000]\n",
      "loss: 0.577759 [32064/80000]\n",
      "loss: 0.467766 [35264/80000]\n",
      "loss: 0.330723 [38464/80000]\n",
      "loss: 0.268652 [41664/80000]\n",
      "loss: 0.399178 [44864/80000]\n",
      "loss: 0.403731 [48064/80000]\n",
      "loss: 0.509936 [51264/80000]\n",
      "loss: 0.358370 [54464/80000]\n",
      "loss: 0.402642 [57664/80000]\n",
      "loss: 0.387516 [60864/80000]\n",
      "loss: 0.418516 [64064/80000]\n",
      "loss: 0.365219 [67264/80000]\n",
      "loss: 0.222672 [70464/80000]\n",
      "loss: 0.438175 [73664/80000]\n",
      "loss: 0.487062 [76864/80000]\n",
      "Test Error:\n",
      " Accuracy: 79.8%, Avg_loss: 0.416069\n",
      "\n",
      "\n",
      "Epoch 17\n",
      "----------------------------------------\n",
      "loss: 0.429845 [   64/80000]\n",
      "loss: 0.315787 [ 3264/80000]\n",
      "loss: 0.357244 [ 6464/80000]\n",
      "loss: 0.358571 [ 9664/80000]\n",
      "loss: 0.336504 [12864/80000]\n",
      "loss: 0.475476 [16064/80000]\n",
      "loss: 0.351663 [19264/80000]\n",
      "loss: 0.441616 [22464/80000]\n",
      "loss: 0.399933 [25664/80000]\n",
      "loss: 0.361107 [28864/80000]\n",
      "loss: 0.333726 [32064/80000]\n",
      "loss: 0.448803 [35264/80000]\n",
      "loss: 0.499613 [38464/80000]\n",
      "loss: 0.347997 [41664/80000]\n",
      "loss: 0.518478 [44864/80000]\n",
      "loss: 0.448047 [48064/80000]\n",
      "loss: 0.284155 [51264/80000]\n",
      "loss: 0.340365 [54464/80000]\n",
      "loss: 0.444100 [57664/80000]\n"
     ]
    }
   ],
   "source": [
    "model = Test(num_node_features_=1, num_edge_features_=1, num_classes=2, num_layers=10, num_neurons_message=5, num_neurons_update=3)\n",
    "model.to(device)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.NAdam(model.parameters())\n",
    "\n",
    "print(f\"\\nWithout Training\\n----------------------------------------\")\n",
    "test(test_dataloader, model, loss_fn, device)\n",
    "\n",
    "epochs = 20\n",
    "for t in range(epochs):\n",
    "    print(f\"\\nEpoch {t+1}\\n----------------------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer, device)\n",
    "    test(test_dataloader, model, loss_fn, device)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicition:  tensor([[-1.3330, -0.6791]], device='cuda:0')\n",
      "label:  tensor([[0., 1.]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "type_ = \"no_cycles\"\n",
    "id_ = 50\n",
    "filename = f\"../GenData/DataCycle/{type_}/{id_}.npz\"\n",
    "graph = np.load(filename)\n",
    "node_list = graph[\"nodes\"]\n",
    "adj_list = graph[\"edges\"]\n",
    "G = nx.Graph()\n",
    "G.add_nodes_from(node_list)\n",
    "G.add_edges_from(adj_list)\n",
    "G = G.to_undirected()\n",
    "\n",
    "label= [1, 0] if type_==\"cycles\" else [0, 1]\n",
    "dat = graphToData(filename, label)\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    dat = dat.to(device)\n",
    "    pred = model(dat)\n",
    "    print(\"predicition: \", pred)\n",
    "    print(\"label: \", dat.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nx.draw(G, with_labels=False, font_weight='bold', node_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
