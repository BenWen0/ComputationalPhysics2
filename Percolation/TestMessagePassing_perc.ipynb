{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch_geometric\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graphToData(dir, file_id):\n",
    "    locs = np.loadtxt(f\"{dir}/{file_id}.locs\")[:, :2] # 0<=locs<=1\n",
    "    n_nodes = 100\n",
    "    locs_int_2d = np.rint(locs*100).astype(int) # 0<= locs_int_2d <= 100\n",
    "    locs_int = locs_int_2d[:, 0]*101 + locs_int_2d[:, 1]\n",
    "    locs_int_max = 101*101\n",
    "    locs_enc = np.zeros(shape=(n_nodes, locs_int_max))\n",
    "    locs_enc[np.arange(n_nodes), locs_int] = 1\n",
    "    adj = list()\n",
    "\n",
    "    with open(f\"{dir}/{file_id}.adj\", \"r\") as file:\n",
    "        # Read each line in the file\n",
    "        n_line = 0\n",
    "        for line in file:\n",
    "            line = line.strip()\n",
    "            neighbors = []\n",
    "            if line != \"None\":\n",
    "                neighbors = [int(id) for id in line.split()]        \n",
    "            for neighbor in neighbors:\n",
    "                adj.append([n_line, neighbor])\n",
    "            n_line += 1\n",
    "    adj_list = np.array(adj, dtype=int)\n",
    "\n",
    "    adj_list_pt = torch.tensor(adj_list, dtype=torch.long) #shape=[num_edges, 2] <- needs to be reshaped (see pyg doc)\n",
    "\n",
    "    #graph = np.load(file)\n",
    "    #num_nodes = len(locs)\n",
    "    num_edges = len(adj_list)#\n",
    "    len_edges = np.sqrt(np.sum((locs[adj_list[:, 0]] - locs[adj_list[:, 1]])**2, axis=1))\n",
    "    #print(len(len_edges), num_edges)\n",
    "    label_ = [1, 0] if dir.split(\"/\")[-1] == \"no\" else [0, 1]\n",
    "    #print(label_)\n",
    "    label = torch.tensor([label_], dtype=torch.float) #shape=[1, num_classes]\n",
    "    #1: \n",
    "    node_values = torch.tensor(locs, dtype=torch.float) #num_node_features = 2, shape=[num_nodes, num_node_features]\n",
    "    #2:\n",
    "    #node_values = torch.tensor(np.identity(100), dtype=torch.float) #num_node_features = 100\n",
    "    #3:\n",
    "    #node_values = torch.tensor(locs_enc, dtype=float)\n",
    "    \n",
    "    #1: \n",
    "    # edge_values = torch.tensor(np.ones(shape=(num_edges, 1)), dtype=torch.float) #shape=[num_edges, num_edge_features]\n",
    "    edge_values = torch.tensor(len_edges.reshape(-1, 1), dtype=torch.float)\n",
    "    \n",
    "    #positions = torch.tensor(graph[\"positions\"], dtype=torch.float) #shape=[num_nodes, 2]\n",
    "    \n",
    "    return Data(x=node_values, edge_index=adj_list_pt.t().contiguous(), edge_attr=edge_values, y=label)\n",
    "\n",
    "def loadData(root_dir):\n",
    "    graphs = list()\n",
    "    for subdir, dirs, files in os.walk(root_dir):\n",
    "        #label= [1, 0] if subdir==\"../GenData/DataCycle/cycles\" else [0, 1]\n",
    "        if len(dirs) > 0:\n",
    "            continue\n",
    "        print(subdir)\n",
    "        ids = list()\n",
    "        for file in tqdm(files):\n",
    "            #print(subdir)\n",
    "            file_id = int(file.split(\".\")[0])\n",
    "            if file_id in ids:\n",
    "                continue\n",
    "            ids.append(file_id)\n",
    "            graph = graphToData(subdir, file_id)\n",
    "            graphs.append(graph)\n",
    "            #print(file.split(\".\")[0])\n",
    "            #print(subdir.split(\"/\")[-1])\n",
    "            #break\n",
    "        print(f\"Number of graphs: {len(ids)}\")\n",
    "        #    path = os.path.join(subdir, file)\n",
    "        #    graphs.append(graphToData(path, label))\n",
    "    return graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNNLayer(torch_geometric.nn.MessagePassing):\n",
    "    def __init__(self, num_node_features_in, num_node_features_out, num_edge_features, \n",
    "                 num_hidden_layers_message, num_hidden_layers_update,\n",
    "                 size_nn_message_hidden, size_nn_update_hidden):\n",
    "        super().__init__(aggr=\"add\", flow=\"source_to_target\") #source_to_target: create message to node i if (j,i) is edge\n",
    "        self.num_node_features_in = num_node_features_in\n",
    "        self.num_node_features_out = num_node_features_out\n",
    "        self.num_edge_features = num_edge_features\n",
    "\n",
    "        #message neural network:\n",
    "        #size of input layers is always 2*number of node features (in) + number of edge features\n",
    "        #size of output layer is always number of node features out\n",
    "        #size of hidden layers is always size_nn_message_hidden\n",
    "        self.layers_message = list()\n",
    "        self.layers_message.append(\n",
    "            torch.nn.Linear(in_features=2*self.num_node_features_in + self.num_edge_features, out_features=size_nn_message_hidden, bias=True)\n",
    "        )\n",
    "        self.layers_message.append(\n",
    "            torch.nn.ReLU()\n",
    "        )\n",
    "        for _ in range(num_hidden_layers_message - 1):\n",
    "            self.layers_message.append(\n",
    "                torch.nn.Linear(in_features=size_nn_message_hidden, out_features=size_nn_message_hidden, bias=True)\n",
    "            )\n",
    "            self.layers_message.append(\n",
    "                torch.nn.ReLU()\n",
    "            )\n",
    "        self.layers_message.append(\n",
    "            torch.nn.Linear(size_nn_message_hidden, out_features=num_node_features_out, bias=True)\n",
    "        )\n",
    "        self.nn_message = torch.nn.ModuleList(self.layers_message)\n",
    "\n",
    "        #update neural network:\n",
    "        #size of input layer is always number of node features out + number of node features in\n",
    "        #size of output layer is always number of node features out\n",
    "        #size of hidden layers is always size_nn_update_hidden\n",
    "\n",
    "        self.layers_update = list()\n",
    "        self.layers_update.append(\n",
    "            torch.nn.Linear(in_features=self.num_node_features_out + self.num_node_features_in, out_features=size_nn_update_hidden, bias=True),\n",
    "        )\n",
    "        self.layers_update.append(\n",
    "            torch.nn.ReLU()\n",
    "        )\n",
    "        for _ in range(num_hidden_layers_update - 1):\n",
    "            self.layers_update.append(\n",
    "                torch.nn.Linear(in_features=size_nn_update_hidden, out_features=size_nn_update_hidden, bias=True),\n",
    "            )\n",
    "            self.layers_update.append(\n",
    "                torch.nn.ReLU()\n",
    "            )\n",
    "        self.layers_update.append(\n",
    "            torch.nn.Linear(in_features=size_nn_update_hidden, out_features=num_node_features_out, bias=True)\n",
    "        )\n",
    "        self.nn_update = torch.nn.ModuleList(self.layers_update)\n",
    "    \n",
    "    def forward(self, x, edge_list, edge_attr):\n",
    "        out = self.propagate(edge_list, x=x, edge_attr=edge_attr) #calls message(), aggregate(), update()\n",
    "        return out #shape = [number of nodes, number of node features]\n",
    "\n",
    "    def message(self, x_i, x_j, edge_attr):\n",
    "        # _i = central node, _j = neighboring node\n",
    "        # x_i,j =[number of edges, number of node features]\n",
    "        # edge_attr = [number of edges, number of edge features]\n",
    "        # the node with node features x_i[k, :] is connected with the nodes having the features x_j[k, :]. The edge connecting these nodes has the features edge_attr[k,:]\n",
    "\n",
    "        vec_in = torch.cat((x_i, x_j, edge_attr), dim = 1) # shape = [num_edges, 2*number of node_features + number of edge_features]\n",
    "        #message = self.nn_message(vec_in) #shape = [num_edges, num node features]\n",
    "        for i in range(len(self.nn_message)):\n",
    "            vec_in = self.nn_message[i](vec_in)\n",
    "        return vec_in #return the message that is passed to node x_i\n",
    "\n",
    "    def update(self, input, x):\n",
    "        #input = output from aggregation step -> input shape = [number of nodes, number of node features]\n",
    "        #x_i shape = [number of nodes, number of node_features]\n",
    "        \n",
    "        vec_in = torch.cat((x, input), dim = 1) #shape = [number of nodes, 2* number of node features]\n",
    "        #updated_input = self.nn_update(vec_in) #shape = [number of nodes, number of node features]\n",
    "        for i in range(len(self.nn_update)):\n",
    "            vec_in = self.nn_update[i](vec_in)\n",
    "        return vec_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Test(torch.nn.Module):\n",
    "    def __init__(self, num_node_features, num_classes, num_edge_features, \n",
    "                 num_additional_layers, num_hidden_layers_message, num_hidden_layers_update,\n",
    "                 width_nn_message_hidden, width_nn_update_hidden):\n",
    "        super().__init__()\n",
    "        #from GNN Layer: \n",
    "        # def __init__(self, num_node_features_in, num_node_features_out, num_edge_features, \n",
    "        #         num_hidden_layers_message, num_hidden_layers_update,\n",
    "        #         size_nn_message_hidden, size_nn_update_hidden):\n",
    "\n",
    "        self.first_layer = GNNLayer(num_node_features, num_classes, num_edge_features,\n",
    "                                    num_hidden_layers_message, num_hidden_layers_update,\n",
    "                                    width_nn_message_hidden, width_nn_update_hidden)\n",
    "        \n",
    "        self.pool = torch_geometric.nn.pool.TopKPooling(in_channels=num_classes, ratio=0.3)\n",
    "\n",
    "        self.layers = list()\n",
    "        for _ in range(num_additional_layers):\n",
    "            self.layers.append(GNNLayer(num_classes, num_classes, num_edge_features, \n",
    "                                        num_hidden_layers_message, num_hidden_layers_update,\n",
    "                                        width_nn_message_hidden, width_nn_update_hidden\n",
    "                                        ))\n",
    "        self.layers = torch.nn.ModuleList(self.layers)\n",
    "        \n",
    "        self.last_layer = GNNLayer(num_classes, num_classes, num_edge_features, \n",
    "                                   num_hidden_layers_message, num_hidden_layers_update,\n",
    "                                   width_nn_message_hidden, width_nn_update_hidden)\n",
    "        \n",
    "    def forward(self, batch_dat):\n",
    "        x, edge_list, edge_attr, batch = batch_dat.x, batch_dat.edge_index, batch_dat.edge_attr, batch_dat.batch\n",
    "        x = self.first_layer(x, edge_list, edge_attr)\n",
    "        x = torch.nn.functional.relu(x)\n",
    "        \n",
    "        x, edge_list, edge_attr, batch, perm, score = self.pool(x, edge_list, edge_attr=edge_attr, batch=batch)\n",
    "\n",
    "        for i in range(len(self.layers)):\n",
    "            x = self.layers[i](x, edge_list, edge_attr)\n",
    "            x = torch.nn.functional.relu(x)\n",
    "\n",
    "        x = self.last_layer(x, edge_list, edge_attr) #shape=[number of nodes, number of node features=number of classe]\n",
    "        logits = torch_geometric.nn.global_mean_pool(x, batch) #shape [number of batches, number of classes]\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(loader, model, loss_fn, optimizer, device, save=False, file_save=\"\"):\n",
    "    total_num_dataset = len(loader.dataset)\n",
    "    model.train()\n",
    "    loss_save = list()\n",
    "    for batch_nr, batch_dat in enumerate(loader):\n",
    "        batch_dat = batch_dat.to(device)\n",
    "        pred = model(batch_dat)\n",
    "        loss = loss_fn(pred, batch_dat.y)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch_nr % 50 == 0:\n",
    "            loss_, current = loss.item(), (batch_nr + 1)*len(batch_dat)\n",
    "            print(f\"loss: {loss_:>7f} [{current:>5d}/{total_num_dataset:>5d}]\")\n",
    "        if save:\n",
    "            loss_ = loss.item()\n",
    "            loss_save.append(loss_)\n",
    "    if save:\n",
    "        np.savetxt(fname=file_save, X=loss_save)\n",
    "\n",
    "\n",
    "def test(loader, model, loss_fn, device, save=False, file_save=\"\"):\n",
    "    size = len(loader.dataset)\n",
    "    num_batches = len(loader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            batch = batch.to(device)\n",
    "            pred = model(batch)\n",
    "            test_loss += loss_fn(pred, batch.y).item()\n",
    "            correct += (pred.argmax(dim=1) == batch.y.argmax(dim=1)).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /=size\n",
    "    print(f\"Test Error:\\n Accuracy: {(100*correct):>0.1f}%, Avg_loss: {test_loss:>8f}\\n\")\n",
    "    if save:\n",
    "        #if not os.path.exists(file_save):\n",
    "        #    os.mknod(file_save)\n",
    "        f = open(file_save, \"a+\")\n",
    "        f.write(f\"{test_loss},{correct}\\n\")\n",
    "        f.close()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./Data/DataSet1/no\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [00:00<00:00, 524.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of graphs: 7\n",
      "./Data/DataSet1/yes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:00<00:00, 353.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of graphs: 8\n",
      "./Data/DataSet2/no\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1644 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1644/1644 [00:03<00:00, 493.67it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of graphs: 822\n",
      "./Data/DataSet2/yes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1586/1586 [00:03<00:00, 487.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of graphs: 793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#load data\n",
    "import random\n",
    "data_list = loadData(\"./Data\")\n",
    "random.shuffle(data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1304\n",
      "DataBatch(x=[800, 2], edge_index=[2, 1924], edge_attr=[1924, 1], y=[8, 2], batch=[800], ptr=[9])\n"
     ]
    }
   ],
   "source": [
    "#data_list = stephen.ThreeDGraphDataset(root='3D_graphs_stephen', n_graphs_per_type=300)\n",
    "\n",
    "train_dataloader = DataLoader(data_list[:int(0.8*len(data_list))], batch_size=8, shuffle=True)\n",
    "test_dataloader = DataLoader(data_list[int(0.8*len(data_list)):], batch_size=8, shuffle=True)\n",
    "print(len(train_dataloader.dataset))\n",
    "print(next(iter(train_dataloader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Without Training\n",
      "----------------------------------------\n",
      "Test Error:\n",
      " Accuracy: 48.8%, Avg_loss: 0.695690\n",
      "\n",
      "\n",
      "Epoch 1\n",
      "----------------------------------------\n",
      "loss: 0.694551 [    8/ 1304]\n",
      "loss: 0.684584 [  408/ 1304]\n",
      "loss: 0.693454 [  808/ 1304]\n",
      "loss: 0.684730 [ 1208/ 1304]\n",
      "Test Error:\n",
      " Accuracy: 51.2%, Avg_loss: 0.693317\n",
      "\n",
      "\n",
      "Epoch 2\n",
      "----------------------------------------\n",
      "loss: 0.732852 [    8/ 1304]\n",
      "loss: 0.685567 [  408/ 1304]\n",
      "loss: 0.689055 [  808/ 1304]\n",
      "loss: 0.694090 [ 1208/ 1304]\n",
      "Test Error:\n",
      " Accuracy: 51.2%, Avg_loss: 0.692905\n",
      "\n",
      "\n",
      "Epoch 3\n",
      "----------------------------------------\n",
      "loss: 0.695390 [    8/ 1304]\n",
      "loss: 0.692185 [  408/ 1304]\n",
      "loss: 0.691648 [  808/ 1304]\n",
      "loss: 0.701149 [ 1208/ 1304]\n",
      "Test Error:\n",
      " Accuracy: 51.2%, Avg_loss: 0.692272\n",
      "\n",
      "\n",
      "Epoch 4\n",
      "----------------------------------------\n",
      "loss: 0.702902 [    8/ 1304]\n",
      "loss: 0.667957 [  408/ 1304]\n",
      "loss: 0.691891 [  808/ 1304]\n",
      "loss: 0.709090 [ 1208/ 1304]\n",
      "Test Error:\n",
      " Accuracy: 62.3%, Avg_loss: 0.690785\n",
      "\n",
      "\n",
      "Epoch 5\n",
      "----------------------------------------\n",
      "loss: 0.689458 [    8/ 1304]\n",
      "loss: 0.691352 [  408/ 1304]\n",
      "loss: 0.715265 [  808/ 1304]\n",
      "loss: 0.670772 [ 1208/ 1304]\n",
      "Test Error:\n",
      " Accuracy: 62.9%, Avg_loss: 0.677354\n",
      "\n",
      "\n",
      "Epoch 6\n",
      "----------------------------------------\n",
      "loss: 0.641432 [    8/ 1304]\n",
      "loss: 0.711596 [  408/ 1304]\n",
      "loss: 0.670992 [  808/ 1304]\n",
      "loss: 0.647226 [ 1208/ 1304]\n",
      "Test Error:\n",
      " Accuracy: 61.3%, Avg_loss: 0.659320\n",
      "\n",
      "\n",
      "Epoch 7\n",
      "----------------------------------------\n",
      "loss: 0.719557 [    8/ 1304]\n",
      "loss: 0.750886 [  408/ 1304]\n",
      "loss: 0.602877 [  808/ 1304]\n",
      "loss: 0.672456 [ 1208/ 1304]\n",
      "Test Error:\n",
      " Accuracy: 54.3%, Avg_loss: 0.677261\n",
      "\n",
      "\n",
      "Epoch 8\n",
      "----------------------------------------\n",
      "loss: 0.767398 [    8/ 1304]\n",
      "loss: 0.557127 [  408/ 1304]\n",
      "loss: 0.502767 [  808/ 1304]\n",
      "loss: 0.736711 [ 1208/ 1304]\n",
      "Test Error:\n",
      " Accuracy: 53.4%, Avg_loss: 0.678180\n",
      "\n",
      "\n",
      "Epoch 9\n",
      "----------------------------------------\n",
      "loss: 0.593456 [    8/ 1304]\n",
      "loss: 0.466695 [  408/ 1304]\n",
      "loss: 0.751092 [  808/ 1304]\n",
      "loss: 0.812950 [ 1208/ 1304]\n",
      "Test Error:\n",
      " Accuracy: 64.4%, Avg_loss: 0.639882\n",
      "\n",
      "\n",
      "Epoch 10\n",
      "----------------------------------------\n",
      "loss: 0.654590 [    8/ 1304]\n",
      "loss: 0.505123 [  408/ 1304]\n",
      "loss: 0.599173 [  808/ 1304]\n",
      "loss: 0.723580 [ 1208/ 1304]\n",
      "Test Error:\n",
      " Accuracy: 65.3%, Avg_loss: 0.639307\n",
      "\n",
      "\n",
      "Epoch 11\n",
      "----------------------------------------\n",
      "loss: 0.712606 [    8/ 1304]\n",
      "loss: 0.500951 [  408/ 1304]\n",
      "loss: 0.837008 [  808/ 1304]\n",
      "loss: 0.599006 [ 1208/ 1304]\n",
      "Test Error:\n",
      " Accuracy: 65.6%, Avg_loss: 0.636653\n",
      "\n",
      "\n",
      "Epoch 12\n",
      "----------------------------------------\n",
      "loss: 0.535105 [    8/ 1304]\n",
      "loss: 0.757832 [  408/ 1304]\n",
      "loss: 0.676543 [  808/ 1304]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mt\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m----------------------------------------\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 14\u001b[0m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m     test(test_dataloader, model, loss_fn, device)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDone\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[32], line 7\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(loader, model, loss_fn, optimizer, device, save, file_save)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_nr, batch_dat \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(loader):\n\u001b[1;32m      6\u001b[0m     batch_dat \u001b[38;5;241m=\u001b[39m batch_dat\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m----> 7\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_dat\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss_fn(pred, batch_dat\u001b[38;5;241m.\u001b[39my)\n\u001b[1;32m     10\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/Programming/PyVenv/ML/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Programming/PyVenv/ML/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[31], line 31\u001b[0m, in \u001b[0;36mTest.forward\u001b[0;34m(self, batch_dat)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch_dat):\n\u001b[1;32m     30\u001b[0m     x, edge_list, edge_attr, batch \u001b[38;5;241m=\u001b[39m batch_dat\u001b[38;5;241m.\u001b[39mx, batch_dat\u001b[38;5;241m.\u001b[39medge_index, batch_dat\u001b[38;5;241m.\u001b[39medge_attr, batch_dat\u001b[38;5;241m.\u001b[39mbatch\n\u001b[0;32m---> 31\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfirst_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_attr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m     x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mrelu(x)\n\u001b[1;32m     34\u001b[0m     x, edge_list, edge_attr, batch, perm, score \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool(x, edge_list, edge_attr\u001b[38;5;241m=\u001b[39medge_attr, batch\u001b[38;5;241m=\u001b[39mbatch)\n",
      "File \u001b[0;32m~/Programming/PyVenv/ML/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Programming/PyVenv/ML/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[5], line 58\u001b[0m, in \u001b[0;36mGNNLayer.forward\u001b[0;34m(self, x, edge_list, edge_attr)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, edge_list, edge_attr):\n\u001b[0;32m---> 58\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpropagate\u001b[49m\u001b[43m(\u001b[49m\u001b[43medge_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_attr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43medge_attr\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m#calls message(), aggregate(), update()\u001b[39;00m\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/Programming/PyVenv/ML/lib/python3.11/site-packages/torch_geometric/nn/conv/message_passing.py:523\u001b[0m, in \u001b[0;36mMessagePassing.propagate\u001b[0;34m(self, edge_index, size, **kwargs)\u001b[0m\n\u001b[1;32m    521\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m res \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    522\u001b[0m         msg_kwargs \u001b[38;5;241m=\u001b[39m res[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(res, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m res\n\u001b[0;32m--> 523\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmessage\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmsg_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_message_forward_hooks\u001b[38;5;241m.\u001b[39mvalues():\n\u001b[1;32m    525\u001b[0m     res \u001b[38;5;241m=\u001b[39m hook(\u001b[38;5;28mself\u001b[39m, (msg_kwargs, ), out)\n",
      "Cell \u001b[0;32mIn[5], line 69\u001b[0m, in \u001b[0;36mGNNLayer.message\u001b[0;34m(self, x_i, x_j, edge_attr)\u001b[0m\n\u001b[1;32m     67\u001b[0m vec_in \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((x_i, x_j, edge_attr), dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;66;03m# shape = [num_edges, 2*number of node_features + number of edge_features]\u001b[39;00m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;66;03m#message = self.nn_message(vec_in) #shape = [num_edges, num node features]\u001b[39;00m\n\u001b[0;32m---> 69\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnn_message)):\n\u001b[1;32m     70\u001b[0m     vec_in \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnn_message[i](vec_in)\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m vec_in\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = Test(num_node_features=2, num_edge_features=1, num_classes=2,\n",
    "             num_additional_layers=1, num_hidden_layers_message=3, num_hidden_layers_update=2,\n",
    "             width_nn_message_hidden=20, width_nn_update_hidden=5)\n",
    "model.to(device)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.NAdam(model.parameters())\n",
    "\n",
    "print(f\"\\nWithout Training\\n----------------------------------------\")\n",
    "test(test_dataloader, model, loss_fn, device)\n",
    "\n",
    "epochs = 30\n",
    "for t in range(epochs):\n",
    "    print(f\"\\nEpoch {t+1}\\n----------------------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer, device)\n",
    "    test(test_dataloader, model, loss_fn, device)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
